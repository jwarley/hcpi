use crate::mdp::{History, Policy};
use rand::seq::SliceRandom;
use rayon::prelude::*;

/// Struct that holds:
/// (a) A representation of a behavior policy using Fourier-basis linear function approximation.
/// (b) A Vec of histories generated by the behavior running on some (possibly unknown) MDP.
/// (c) A Vec of (state, action) probabilities for the first history, generated by the behavior
///     policy, which are only used to test that our policy representation is correct.
#[derive(Debug, Clone)]
pub struct PolicyData {
    pub state_dim: u8,
    pub n_actions: u32,
    pub fourier_deg: u8,
    pub pi_b: Policy,
    pub num_eps: usize,
    pub hists: Vec<History>,
    test_policy_probs: Vec<f64>,
}

impl PolicyData {
    fn new() -> Self {
        PolicyData {
            state_dim: 0,
            n_actions: 0,
            fourier_deg: 0,
            pi_b: Vec::new(),
            num_eps: 0,
            hists: Vec::new(),
            test_policy_probs: Vec::new(),
        }
    }

    /// Read the policy data from a csv file
    pub fn from_file(path: &str) -> PolicyData {
        let mut rdr = csv::ReaderBuilder::new()
            .has_headers(false)
            .flexible(true)
            .from_path(path)
            .unwrap();

        let mut pd = PolicyData::new();

        // Read the state dimension, action set size, and Fourier basis degree
        pd.state_dim = rdr.records().next().unwrap().unwrap()[0].parse().unwrap();
        pd.n_actions = rdr.records().next().unwrap().unwrap()[0].parse().unwrap();
        pd.fourier_deg = rdr.records().next().unwrap().unwrap()[0].parse().unwrap();

        // Read the behavior policy parameters
        let pi_b = rdr.records().next().unwrap().unwrap();
        for weight in pi_b.into_iter() {
            pd.pi_b.push(weight.trim().parse::<f64>().unwrap());
        }

        // Read the number of episodes and the history data
        pd.num_eps = rdr.records().next().unwrap().unwrap()[0].parse().unwrap();
        for _ in 0..pd.num_eps {
            let record = rdr.records().next().unwrap().unwrap();
            pd.hists
                .push(History::from_seq(record, pd.state_dim as u32))
        }

        // Read the behavior policy parameters
        let pi_b_probs = rdr.records().next().unwrap().unwrap();
        for p in pi_b_probs.into_iter() {
            pd.test_policy_probs.push(p.trim().parse::<f64>().unwrap());
        }

        pd
    }

    /// Compute the observed average return of pi_b
    pub fn pi_b_avg_return(&self) -> f64 {
        self.hists
            .par_iter()
            .map(|h| h.rewards.iter().sum::<f64>())
            .sum::<f64>()
            / self.hists.len() as f64
    }

    /// Construct two new PolicyData objects, one containing `n` elements at random,
    /// and the other containing all the rest.
    /// This leaves the original data intact; everything is copied to the new objects.
    pub fn random_split(&self, n: usize) -> (Self, Self) {
        let rng = &mut rand::thread_rng();
        let mut h_copy = self.hists.clone();
        let (h1, h2) = h_copy.partial_shuffle(rng, n);

        let pd1 = Self {
            hists: h1.to_vec(),
            num_eps: h1.len(),
            pi_b: self.pi_b.clone(),
            test_policy_probs: self.test_policy_probs.clone(),
            ..*self
        };
        let pd2 = Self {
            hists: h2.to_vec(),
            num_eps: h2.len(),
            pi_b: self.pi_b.clone(),
            test_policy_probs: self.test_policy_probs.clone(),
            ..*self
        };

        (pd1, pd2)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    /// Test that the input data was self-consistent to make sure our policy representation is
    /// accurate.
    pub fn check_consistent(data: &PolicyData) {
        println!("Running consistency test for input data");
        // Test that the dimension of pi_b is consistent with other values
        assert!(
            data.pi_b.len()
                == (data.n_actions * (data.fourier_deg + 1).pow(data.state_dim.into()) as u32)
                    as usize
        );

        // Test that the policy outputs match the sample values
        let fp = crate::mdp::FourierPolicy::new(
            data.fourier_deg,
            data.state_dim,
            data.pi_b.clone(),
            data.n_actions,
        );
        let h = &data.hists[0];
        let our_probs: Vec<f64> = (0..(h.states.len()))
            .map(|t| fp.eval(&h.states[t], h.actions[t]))
            .collect();
        dbg!(our_probs.clone());
        dbg!(data.test_policy_probs.clone());
        for (ours, theirs) in our_probs.iter().zip(data.test_policy_probs.clone()) {
            dbg!(f64::abs((ours - theirs) / theirs));
            assert!(f64::abs((ours - theirs) / theirs) <= 1e-5);
        }
    }

    #[test]
    fn test_policy_repr() {
        let data_path = "data.csv";
        println!("Loading behavior policy data from {}", data_path);
        let d = PolicyData::from_file(data_path);
        check_consistent(&d);
    }
}
